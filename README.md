## üèóÔ∏è Estrutura do Projeto

O pipeline segue a **Arquitetura Medalh√£o**, garantindo qualidade e governan√ßa em cada etapa:

### ü•â Camada Raw (Ingest√£o)
- **Origem**: Dados sint√©ticos gerados via biblioteca `Faker` (Python).
- **Tecnologia**: Databricks Volumes & PySpark.
- **Diferencial**: Gera√ß√£o din√¢mica de 200k a 1MM registros por lote para teste de carga.

### ü•à Camada Silver (Limpeza & Hist√≥rico)
- **Processamento**: Streaming incremental com **Auto Loader** (`cloudFiles`).
- **Resili√™ncia**: Configurado com **Schema Evolution** (`addNewColumns`) e `mergeSchema`.
- **Linhagem**: Inclus√£o de metadados (`_metadata`) para rastreabilidade de arquivos e timestamps de modifica√ß√£o.
- **Hist√≥rico**: Armazenamento em formato Delta mantendo o hist√≥rico completo de altera√ß√µes (Append Mode).

### ü•á Camada Gold (Neg√≥cio & Insights)
- **Objetivo**: Tabela de `clientes_contatos_validos` pronta para consumo em BI.
- **Transforma√ß√µes**:
  - **Deduplica√ß√£o**: Uso de `QUALIFY ROW_NUMBER()` para extrair apenas o registro mais recente por CPF.
  - **Data Quality**: Valida√ß√£o de formato de telefone brasileiro via Regex e exclus√£o de prefixos de centrais de atendimento (0800/0300).
  - **UX de Dados**: Remo√ß√£o de metadados t√©cnicos e cria√ß√£o de colunas amig√°veis de "√∫ltima atualiza√ß√£o".

## üõ†Ô∏è Tecnologias Principais
- **Databricks Serverless** (Workflow Orchestration)
- **Unity Catalog** (Governan√ßa e Volumes)
- **Delta Lake** (Transa√ß√µes ACID e Schema Evolution)
- **Auto Loader** (Ingest√£o otimizada de arquivos)
- **Spark SQL & PySpark**
